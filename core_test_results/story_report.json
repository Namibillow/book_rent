{
  "[carlos ruiz zafon](PERSON)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[Tales of the Cthulhu Mythos](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "action_reset_slots": {
    "precision": 0.9615384615384616,
    "recall": 1.0,
    "f1-score": 0.9803921568627451,
    "support": 25
  },
  "[1986](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "[f scott fitzgerald](PERSON)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[phone](contact_type)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "select_from_list": {
    "precision": 1.0,
    "recall": 0.6,
    "f1-score": 0.7499999999999999,
    "support": 5
  },
  "action_tell_contact_info": {
    "precision": 0.8,
    "recall": 1.0,
    "f1-score": 0.888888888888889,
    "support": 4
  },
  "[Carlos Ruiz Zaf√≥n](PERSON)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[bollow](PERSON)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[jungle rock blues](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "greet": {
    "precision": 1.0,
    "recall": 0.96875,
    "f1-score": 0.9841269841269841,
    "support": 32
  },
  "utter_provided_services": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[george orwell](PERSON)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "utter_confirm_to_borrow": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 11
  },
  "[phone number](phone)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "action_repeat": {
    "precision": 0.8333333333333334,
    "recall": 1.0,
    "f1-score": 0.9090909090909091,
    "support": 5
  },
  "utter_help": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 31
  },
  "faq_total_allowance": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3
  },
  "[phone number](contact_type)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "user_inventory_check_return": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 9
  },
  "[the watcher in the shadows](book_title)": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 1
  },
  "[george orwell](book_title)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "[the harry potter and sorcerer of the stone](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[tiny pretty things](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "repeat_again": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6
  },
  "utter_yourwelcome": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8
  },
  "action_search_book": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 27
  },
  "action_perform_borrow": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "[the lion](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "action_tell_opentime": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8
  },
  "[the hobbit do we](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "thanks": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8
  },
  "[first](ordinal)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "faq_check_location": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "faq_check_open": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8
  },
  "contact_library": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 13
  },
  "help": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[email address](email)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "utter_greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 32
  },
  "[the harry potter and sorcery of the stone](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "affirm": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 16
  },
  "[the first]{\"entity\": \"time\", \"value\": \"2022-02-01T00:00:00.000-08:00\"}": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "[harry potter](book_title)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "search_book_form": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 42
  },
  "deny": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8
  },
  "user_inventory_check_remaining": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5
  },
  "action_deactivate_loop": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3
  },
  "out_of_scope": {
    "precision": 1.0,
    "recall": 0.625,
    "f1-score": 0.7692307692307693,
    "support": 8
  },
  "utter_search_book_greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6
  },
  "utter_ask_list_have_desired": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 14
  },
  "[narnia](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "utter_goodbye": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6
  },
  "[we have](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[mystery novel called the watcher in the shadows](book_title)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "utter_sorry_to_hear_that": {
    "precision": 0.75,
    "recall": 1.0,
    "f1-score": 0.8571428571428571,
    "support": 3
  },
  "goodbye": {
    "precision": 1.0,
    "recall": 0.6666666666666666,
    "f1-score": 0.8,
    "support": 6
  },
  "user_inventory_check_current_borrowing": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10
  },
  "[j k rowling](PERSON)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "action_listen": {
    "precision": 1.0,
    "recall": 0.9895287958115183,
    "f1-score": 0.9947368421052631,
    "support": 191
  },
  "denu": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "[The Lion, the Witch and the Wardrobe](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "contact_form": {
    "precision": 0.8666666666666667,
    "recall": 1.0,
    "f1-score": 0.9285714285714286,
    "support": 13
  },
  "[last](ordinal)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "utter_library_location": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 1
  },
  "action_assign_book_info_to_form": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 21
  },
  "[the great gatsby](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "[the before the coffee gets cold](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "select_from_list_form": {
    "precision": 0.9473684210526315,
    "recall": 1.0,
    "f1-score": 0.972972972972973,
    "support": 18
  },
  "[jurrassic world](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "utter_library_email": {
    "precision": 1.0,
    "recall": 0.5,
    "f1-score": 0.6666666666666666,
    "support": 2
  },
  "utter_library_phone": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "[the ring](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "action_restart": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6
  },
  "search_book": {
    "precision": 0.8571428571428571,
    "recall": 1.0,
    "f1-score": 0.923076923076923,
    "support": 6
  },
  "[stephen king](PERSON)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[email](contact_type)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "terminate_conversation": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4
  },
  "[hobbit](book_title)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "[life of pie](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "[harry potter](PERSON)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "[series](book_title)": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "[the harry potter and chamber of secrets](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "inform_book_info": {
    "precision": 0.8888888888888888,
    "recall": 1.0,
    "f1-score": 0.9411764705882353,
    "support": 40
  },
  "[osamu dasai](PERSON)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "utter_iamabot": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[first night of summer](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "action_user_inventory": {
    "precision": 1.0,
    "recall": 0.9583333333333334,
    "f1-score": 0.9787234042553191,
    "support": 24
  },
  "[the prague cemetery](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "utter_ok": {
    "precision": 1.0,
    "recall": 0.8888888888888888,
    "f1-score": 0.9411764705882353,
    "support": 9
  },
  "[third]{\"entity\": \"ordinal\", \"value\": 3}": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "[the prisoner of heaven](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "action_default_fallback": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "None": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 36
  },
  "utter_out_of_scope": {
    "precision": 1.0,
    "recall": 0.8333333333333334,
    "f1-score": 0.9090909090909091,
    "support": 6
  },
  "bot_challenge": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "utter_total_allowance": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3
  },
  "[the tales of beedle the bard](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[lord of the rings](book_title)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "[email address]{\"entity\": \"contact_type\", \"value\": \"email\"}": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 1
  },
  "micro avg": {
    "precision": 0.9675324675324676,
    "recall": 0.9174876847290641,
    "f1-score": 0.9418457648546144,
    "support": 812
  },
  "macro avg": {
    "precision": 0.7940493862862285,
    "recall": 0.8003050101803373,
    "f1-score": 0.7919506465325911,
    "support": 812
  },
  "weighted avg": {
    "precision": 0.9189320679176785,
    "recall": 0.9174876847290641,
    "f1-score": 0.9161221431702656,
    "support": 812
  },
  "conversation_accuracy": {
    "accuracy": 0.41818181818181815,
    "correct": 23,
    "with_warnings": 2,
    "total": 55
  }
}